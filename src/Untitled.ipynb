{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50346703-b6b2-4a24-8d80-451455424656",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "sns.set_style('darkgrid')\n",
    "pd.set_option('display.max_columns', None)\n",
    "import datetime, warnings, scipy\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import imblearn\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e950e17-64df-4d76-8ddd-3cb5e249c711",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import packages for hyperparameters tuning\n",
    "#from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "dataset = pd.read_csv('../data/training_set/TRAIN_ME_carriers.csv')\n",
    "data = dataset.copy()\n",
    "data['mkt_carrier'].unique()\n",
    "\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "data['mkt_carrier'] = le.fit_transform(data['mkt_carrier'])\n",
    "\n",
    "data = data.drop(['Unnamed: 0'],axis=1)\n",
    "data['flight_status'] = (data['arr_delay'] > 15).replace([True,False],[1,0])\n",
    "data.drop(['arr_delay'],axis=1,inplace=True)\n",
    "data['speed']=data['distance']/data['crs_elapsed_time']\n",
    "\n",
    "# sample1 = data.loc[data['flight_status'] == 1]\n",
    "# sample2 = data.loc[data['flight_status'] == 0]\n",
    "# sample_2 = sample2.sample(n=757903)\n",
    "# sample = sample1.append(sample_2)\n",
    "\n",
    "sample = data.sample(n=2000)\n",
    "\n",
    "\n",
    "X = sample.drop(['flight_status'], axis=1)\n",
    "y = sample['flight_status']\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62ab9c34-5cb2-433e-80ce-eab4c9975ce0",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[09:57:55] /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/common/io.cc:102: Opening xgb_classifier.json failed: No such file or directory\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x0000001a1c1230fe dmlc::LogMessageFatal::~LogMessageFatal() + 110\n  [bt] (1) 2   libxgboost.dylib                    0x0000001a1c146e8c xgboost::common::LoadSequentialFile(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, bool) + 828\n  [bt] (2) 3   libxgboost.dylib                    0x0000001a1c11b946 XGBoosterLoadModel + 614\n  [bt] (3) 4   libffi.6.dylib                      0x00000001053ca934 ffi_call_unix64 + 76\n  [bt] (4) 5   ???                                 0x00007ffeeb3b9d80 0x0 + 140732844973440\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7d2a20ddf8eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xgb_classifier.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/lighthouselabs_env/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(self, fname)\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_Booster'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'n_jobs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'scikit_learn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmeta\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/lighthouselabs_env/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(self, fname)\u001b[0m\n\u001b[1;32m   1727\u001b[0m             \u001b[0;31m# from URL.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m             _check_call(_LIB.XGBoosterLoadModel(\n\u001b[0;32m-> 1729\u001b[0;31m                 self.handle, c_str(os.fspath(fname))))\n\u001b[0m\u001b[1;32m   1730\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/lighthouselabs_env/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \"\"\"\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [09:57:55] /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/common/io.cc:102: Opening xgb_classifier.json failed: No such file or directory\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x0000001a1c1230fe dmlc::LogMessageFatal::~LogMessageFatal() + 110\n  [bt] (1) 2   libxgboost.dylib                    0x0000001a1c146e8c xgboost::common::LoadSequentialFile(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, bool) + 828\n  [bt] (2) 3   libxgboost.dylib                    0x0000001a1c11b946 XGBoosterLoadModel + 614\n  [bt] (3) 4   libffi.6.dylib                      0x00000001053ca934 ffi_call_unix64 + 76\n  [bt] (4) 5   ???                                 0x00007ffeeb3b9d80 0x0 + 140732844973440\n\n"
     ]
    }
   ],
   "source": [
    "model2 = xgb.XGBClassifier()\n",
    "model2.load_model(\"xgb_classifier.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25e131f5-473f-4616-b60e-de417d2f5b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SMOTE sampling\n",
    "\n",
    "sm = SMOTE(random_state = 2)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "204a79e9-5ba7-49da-98f2-7be31e501b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2576,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91cc8fb-4151-4189-8441-158972ffe617",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### XGBoost\n",
    "model_imb = xgb.XGBClassifier(alpha=1,\n",
    "                             learning_rate = 0.1,\n",
    "                             max_depth = 6,\n",
    "                             min_child_weight = 9,\n",
    "                             n_estimators = 100,\n",
    "                             objective = 'binary:logistic',\n",
    "                             scale_pos_weight = 0.75,\n",
    "                             subsample = 0.7)\n",
    "                                   \n",
    "model_imb.fit(X, y)\n",
    "\n",
    "print(\"Accuracy on training set: {:.2f}\".format(model_imb.score(X_train, y_train) * 100))\n",
    "print(\"Accuracy on validation set: {:.2f}\".format(model_imb.score(X_test, y_test) * 100))\n",
    "\n",
    "xgb_predict = model_imb.predict(X_test)\n",
    "xgb_predict\n",
    "\n",
    "print(confusion_matrix(y_test,xgb_predict))\n",
    "print(classification_report(y_test,xgb_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lighthouselabs_env",
   "language": "python",
   "name": "lighthouselabs_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
